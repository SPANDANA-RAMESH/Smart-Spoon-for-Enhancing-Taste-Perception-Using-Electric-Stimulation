{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3200 images belonging to 80 classes.\n",
      "Found 800 images belonging to 80 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bennett Varghese\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bennett Varghese\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 243ms/step - accuracy: 0.0200 - loss: 4.8546 - val_accuracy: 0.0100 - val_loss: 4.3471\n",
      "Epoch 2/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 229ms/step - accuracy: 0.0218 - loss: 4.3355 - val_accuracy: 0.0388 - val_loss: 4.2747\n",
      "Epoch 3/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 228ms/step - accuracy: 0.0503 - loss: 4.1603 - val_accuracy: 0.0800 - val_loss: 4.0739\n",
      "Epoch 4/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 229ms/step - accuracy: 0.1536 - loss: 3.6432 - val_accuracy: 0.1225 - val_loss: 3.8581\n",
      "Epoch 5/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 232ms/step - accuracy: 0.2611 - loss: 3.0178 - val_accuracy: 0.1663 - val_loss: 3.7497\n",
      "Epoch 6/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 234ms/step - accuracy: 0.3851 - loss: 2.4239 - val_accuracy: 0.2062 - val_loss: 3.7342\n",
      "Epoch 7/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 235ms/step - accuracy: 0.5090 - loss: 1.8216 - val_accuracy: 0.2325 - val_loss: 3.7393\n",
      "Epoch 8/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 233ms/step - accuracy: 0.5819 - loss: 1.5305 - val_accuracy: 0.2338 - val_loss: 3.7701\n",
      "Epoch 9/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 235ms/step - accuracy: 0.6677 - loss: 1.2342 - val_accuracy: 0.2475 - val_loss: 3.9042\n",
      "Epoch 10/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 234ms/step - accuracy: 0.7057 - loss: 1.0274 - val_accuracy: 0.2575 - val_loss: 3.9733\n",
      "Epoch 11/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 233ms/step - accuracy: 0.7412 - loss: 0.8950 - val_accuracy: 0.2625 - val_loss: 3.9592\n",
      "Epoch 12/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 236ms/step - accuracy: 0.7744 - loss: 0.8002 - val_accuracy: 0.2738 - val_loss: 4.1464\n",
      "Epoch 13/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 237ms/step - accuracy: 0.7910 - loss: 0.6855 - val_accuracy: 0.2775 - val_loss: 4.2699\n",
      "Epoch 14/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 239ms/step - accuracy: 0.8061 - loss: 0.6575 - val_accuracy: 0.2663 - val_loss: 4.5564\n",
      "Epoch 15/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 236ms/step - accuracy: 0.8369 - loss: 0.5707 - val_accuracy: 0.2637 - val_loss: 4.4737\n",
      "Epoch 16/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 236ms/step - accuracy: 0.8307 - loss: 0.5705 - val_accuracy: 0.2575 - val_loss: 4.7806\n",
      "Epoch 17/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 229ms/step - accuracy: 0.8407 - loss: 0.5222 - val_accuracy: 0.2750 - val_loss: 4.7530\n",
      "Epoch 18/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 234ms/step - accuracy: 0.8379 - loss: 0.5086 - val_accuracy: 0.2700 - val_loss: 4.8736\n",
      "Epoch 19/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 234ms/step - accuracy: 0.8495 - loss: 0.4679 - val_accuracy: 0.2637 - val_loss: 4.6875\n",
      "Epoch 20/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 233ms/step - accuracy: 0.8577 - loss: 0.4971 - val_accuracy: 0.2600 - val_loss: 4.7169\n",
      "Epoch 21/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 246ms/step - accuracy: 0.8633 - loss: 0.4461 - val_accuracy: 0.2725 - val_loss: 4.6933\n",
      "Epoch 22/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 253ms/step - accuracy: 0.8670 - loss: 0.4360 - val_accuracy: 0.2688 - val_loss: 4.8742\n",
      "Epoch 23/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 240ms/step - accuracy: 0.8891 - loss: 0.3567 - val_accuracy: 0.2612 - val_loss: 4.9394\n",
      "Epoch 24/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 239ms/step - accuracy: 0.8667 - loss: 0.4227 - val_accuracy: 0.2675 - val_loss: 4.9764\n",
      "Epoch 25/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 235ms/step - accuracy: 0.8768 - loss: 0.3771 - val_accuracy: 0.2763 - val_loss: 5.1558\n",
      "Epoch 26/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 249ms/step - accuracy: 0.8874 - loss: 0.3447 - val_accuracy: 0.2650 - val_loss: 5.3664\n",
      "Epoch 27/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 234ms/step - accuracy: 0.8811 - loss: 0.3618 - val_accuracy: 0.2738 - val_loss: 5.1982\n",
      "Epoch 28/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 234ms/step - accuracy: 0.8799 - loss: 0.3668 - val_accuracy: 0.2800 - val_loss: 5.0266\n",
      "Epoch 29/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 234ms/step - accuracy: 0.8881 - loss: 0.3295 - val_accuracy: 0.2650 - val_loss: 5.4966\n",
      "Epoch 30/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 233ms/step - accuracy: 0.8924 - loss: 0.3101 - val_accuracy: 0.2713 - val_loss: 5.5226\n",
      "Epoch 31/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 234ms/step - accuracy: 0.8943 - loss: 0.3450 - val_accuracy: 0.2850 - val_loss: 5.2994\n",
      "Epoch 32/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 235ms/step - accuracy: 0.8902 - loss: 0.3418 - val_accuracy: 0.2812 - val_loss: 5.5025\n",
      "Epoch 33/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 233ms/step - accuracy: 0.8967 - loss: 0.3490 - val_accuracy: 0.2725 - val_loss: 5.1334\n",
      "Epoch 34/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 234ms/step - accuracy: 0.9125 - loss: 0.2747 - val_accuracy: 0.2713 - val_loss: 5.3981\n",
      "Epoch 35/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 234ms/step - accuracy: 0.9127 - loss: 0.2586 - val_accuracy: 0.2700 - val_loss: 5.5722\n",
      "Epoch 36/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 233ms/step - accuracy: 0.9009 - loss: 0.2848 - val_accuracy: 0.2700 - val_loss: 5.4947\n",
      "Epoch 37/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 244ms/step - accuracy: 0.9033 - loss: 0.3019 - val_accuracy: 0.2725 - val_loss: 5.6852\n",
      "Epoch 38/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 239ms/step - accuracy: 0.8925 - loss: 0.3384 - val_accuracy: 0.2700 - val_loss: 5.1967\n",
      "Epoch 39/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 233ms/step - accuracy: 0.9070 - loss: 0.2887 - val_accuracy: 0.2738 - val_loss: 5.3413\n",
      "Epoch 40/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 234ms/step - accuracy: 0.9073 - loss: 0.2959 - val_accuracy: 0.2663 - val_loss: 5.7020\n",
      "Epoch 41/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 234ms/step - accuracy: 0.9209 - loss: 0.2686 - val_accuracy: 0.2763 - val_loss: 5.3934\n",
      "Epoch 42/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 232ms/step - accuracy: 0.9157 - loss: 0.2686 - val_accuracy: 0.2700 - val_loss: 5.7811\n",
      "Epoch 43/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 234ms/step - accuracy: 0.9126 - loss: 0.2631 - val_accuracy: 0.2663 - val_loss: 5.8221\n",
      "Epoch 44/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 230ms/step - accuracy: 0.9118 - loss: 0.2638 - val_accuracy: 0.2788 - val_loss: 5.4307\n",
      "Epoch 45/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 231ms/step - accuracy: 0.9170 - loss: 0.2660 - val_accuracy: 0.2750 - val_loss: 5.9450\n",
      "Epoch 46/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 253ms/step - accuracy: 0.9181 - loss: 0.2250 - val_accuracy: 0.2788 - val_loss: 5.6259\n",
      "Epoch 47/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 233ms/step - accuracy: 0.9174 - loss: 0.2754 - val_accuracy: 0.2713 - val_loss: 5.5395\n",
      "Epoch 48/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 251ms/step - accuracy: 0.9036 - loss: 0.2642 - val_accuracy: 0.2650 - val_loss: 5.6926\n",
      "Epoch 49/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 243ms/step - accuracy: 0.9315 - loss: 0.2340 - val_accuracy: 0.2675 - val_loss: 5.7781\n",
      "Epoch 50/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 321ms/step - accuracy: 0.9081 - loss: 0.2800 - val_accuracy: 0.2713 - val_loss: 5.5125\n",
      "Epoch 51/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 233ms/step - accuracy: 0.9227 - loss: 0.2260 - val_accuracy: 0.2713 - val_loss: 6.0975\n",
      "Epoch 52/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 232ms/step - accuracy: 0.9219 - loss: 0.2337 - val_accuracy: 0.2862 - val_loss: 5.5965\n",
      "Epoch 53/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 233ms/step - accuracy: 0.9204 - loss: 0.2082 - val_accuracy: 0.2738 - val_loss: 5.7215\n",
      "Epoch 54/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 236ms/step - accuracy: 0.9332 - loss: 0.2019 - val_accuracy: 0.2700 - val_loss: 6.2520\n",
      "Epoch 55/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 242ms/step - accuracy: 0.9071 - loss: 0.2714 - val_accuracy: 0.2663 - val_loss: 5.6389\n",
      "Epoch 56/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 231ms/step - accuracy: 0.9282 - loss: 0.1966 - val_accuracy: 0.2763 - val_loss: 6.0053\n",
      "Epoch 57/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 240ms/step - accuracy: 0.9166 - loss: 0.2461 - val_accuracy: 0.2725 - val_loss: 5.6052\n",
      "Epoch 58/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 233ms/step - accuracy: 0.9168 - loss: 0.2431 - val_accuracy: 0.2725 - val_loss: 5.7068\n",
      "Epoch 59/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 232ms/step - accuracy: 0.9272 - loss: 0.2205 - val_accuracy: 0.2763 - val_loss: 5.3760\n",
      "Epoch 60/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 238ms/step - accuracy: 0.9301 - loss: 0.2074 - val_accuracy: 0.2637 - val_loss: 5.6580\n",
      "Epoch 61/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 232ms/step - accuracy: 0.9239 - loss: 0.2447 - val_accuracy: 0.2738 - val_loss: 6.2993\n",
      "Epoch 62/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 242ms/step - accuracy: 0.9204 - loss: 0.2435 - val_accuracy: 0.2763 - val_loss: 5.9131\n",
      "Epoch 63/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 233ms/step - accuracy: 0.9356 - loss: 0.1853 - val_accuracy: 0.2775 - val_loss: 6.0116\n",
      "Epoch 64/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 237ms/step - accuracy: 0.9243 - loss: 0.2177 - val_accuracy: 0.2625 - val_loss: 6.4745\n",
      "Epoch 65/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 237ms/step - accuracy: 0.9324 - loss: 0.2062 - val_accuracy: 0.2625 - val_loss: 5.8533\n",
      "Epoch 66/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 231ms/step - accuracy: 0.9347 - loss: 0.2073 - val_accuracy: 0.2775 - val_loss: 6.4339\n",
      "Epoch 67/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 232ms/step - accuracy: 0.9231 - loss: 0.2073 - val_accuracy: 0.2713 - val_loss: 6.5319\n",
      "Epoch 68/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 233ms/step - accuracy: 0.9371 - loss: 0.1900 - val_accuracy: 0.2750 - val_loss: 5.9532\n",
      "Epoch 69/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 231ms/step - accuracy: 0.9330 - loss: 0.1922 - val_accuracy: 0.2675 - val_loss: 5.8812\n",
      "Epoch 70/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 234ms/step - accuracy: 0.9299 - loss: 0.2062 - val_accuracy: 0.2625 - val_loss: 6.3100\n",
      "Epoch 71/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 232ms/step - accuracy: 0.9364 - loss: 0.1886 - val_accuracy: 0.2725 - val_loss: 6.2909\n",
      "Epoch 72/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 233ms/step - accuracy: 0.9364 - loss: 0.2096 - val_accuracy: 0.2725 - val_loss: 6.2584\n",
      "Epoch 73/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 233ms/step - accuracy: 0.9368 - loss: 0.1765 - val_accuracy: 0.2688 - val_loss: 5.7397\n",
      "Epoch 74/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 233ms/step - accuracy: 0.9250 - loss: 0.2115 - val_accuracy: 0.2713 - val_loss: 5.8153\n",
      "Epoch 75/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 239ms/step - accuracy: 0.9400 - loss: 0.1714 - val_accuracy: 0.2688 - val_loss: 6.1973\n",
      "Epoch 76/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 233ms/step - accuracy: 0.9402 - loss: 0.1678 - val_accuracy: 0.2738 - val_loss: 5.8819\n",
      "Epoch 77/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 231ms/step - accuracy: 0.9354 - loss: 0.2091 - val_accuracy: 0.2763 - val_loss: 6.2601\n",
      "Epoch 78/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 230ms/step - accuracy: 0.9453 - loss: 0.1606 - val_accuracy: 0.2688 - val_loss: 6.8081\n",
      "Epoch 79/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 232ms/step - accuracy: 0.9174 - loss: 0.2082 - val_accuracy: 0.2600 - val_loss: 6.2459\n",
      "Epoch 80/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 231ms/step - accuracy: 0.9389 - loss: 0.1780 - val_accuracy: 0.2725 - val_loss: 6.1041\n",
      "Epoch 81/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 247ms/step - accuracy: 0.9265 - loss: 0.2029 - val_accuracy: 0.2750 - val_loss: 6.2572\n",
      "Epoch 82/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 239ms/step - accuracy: 0.9400 - loss: 0.1865 - val_accuracy: 0.2700 - val_loss: 6.0065\n",
      "Epoch 83/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 236ms/step - accuracy: 0.9456 - loss: 0.1504 - val_accuracy: 0.2688 - val_loss: 6.2433\n",
      "Epoch 84/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 233ms/step - accuracy: 0.9349 - loss: 0.1878 - val_accuracy: 0.2763 - val_loss: 6.1012\n",
      "Epoch 85/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 272ms/step - accuracy: 0.9410 - loss: 0.1870 - val_accuracy: 0.2837 - val_loss: 6.2419\n",
      "Epoch 86/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 235ms/step - accuracy: 0.9435 - loss: 0.1711 - val_accuracy: 0.2825 - val_loss: 6.5769\n",
      "Epoch 87/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 231ms/step - accuracy: 0.9260 - loss: 0.2008 - val_accuracy: 0.2700 - val_loss: 6.1817\n",
      "Epoch 88/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 233ms/step - accuracy: 0.9287 - loss: 0.1785 - val_accuracy: 0.2725 - val_loss: 6.0254\n",
      "Epoch 89/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 234ms/step - accuracy: 0.9542 - loss: 0.1600 - val_accuracy: 0.2788 - val_loss: 6.3727\n",
      "Epoch 90/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 232ms/step - accuracy: 0.9449 - loss: 0.1720 - val_accuracy: 0.2713 - val_loss: 6.1731\n",
      "Epoch 91/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 232ms/step - accuracy: 0.9490 - loss: 0.1492 - val_accuracy: 0.2700 - val_loss: 6.0781\n",
      "Epoch 92/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 233ms/step - accuracy: 0.9378 - loss: 0.1964 - val_accuracy: 0.2763 - val_loss: 6.2484\n",
      "Epoch 93/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 230ms/step - accuracy: 0.9401 - loss: 0.1716 - val_accuracy: 0.2900 - val_loss: 6.2677\n",
      "Epoch 94/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 235ms/step - accuracy: 0.9465 - loss: 0.1580 - val_accuracy: 0.2837 - val_loss: 6.2126\n",
      "Epoch 95/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 232ms/step - accuracy: 0.9471 - loss: 0.1595 - val_accuracy: 0.2775 - val_loss: 5.7853\n",
      "Epoch 96/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 234ms/step - accuracy: 0.9430 - loss: 0.1650 - val_accuracy: 0.2700 - val_loss: 6.8126\n",
      "Epoch 97/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 234ms/step - accuracy: 0.9478 - loss: 0.1525 - val_accuracy: 0.2637 - val_loss: 6.3056\n",
      "Epoch 98/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 233ms/step - accuracy: 0.9504 - loss: 0.1540 - val_accuracy: 0.2775 - val_loss: 6.3708\n",
      "Epoch 99/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 231ms/step - accuracy: 0.9313 - loss: 0.1793 - val_accuracy: 0.2713 - val_loss: 6.4105\n",
      "Epoch 100/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 241ms/step - accuracy: 0.9526 - loss: 0.1357 - val_accuracy: 0.2750 - val_loss: 6.4223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2806b59a8d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Image preprocessing\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    'data',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    'data',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(train_gen.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_gen, validation_data=val_gen, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Predicted: dal_tadka\n",
      "Nutritional Info: {'Calories(kcal)': 180, 'Carbohydrates(g)': 22, 'Protein(g)': 8, 'Fats(g)': 7, 'Sugar(g)': 2}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load CSV data\n",
    "nutri_df = pd.read_csv('indian_dishes_nutritional_values.csv')\n",
    "nutri_dict = nutri_df.set_index(\"Dish Name\").to_dict(orient=\"index\")\n",
    "\n",
    "# Load and preprocess input image\n",
    "img = image.load_img(\"data/misi_roti/0fa205266b.jpg\", target_size=(128, 128))\n",
    "img_array = np.expand_dims(image.img_to_array(img) / 255.0, axis=0)\n",
    "\n",
    "# Predict\n",
    "pred = model.predict(img_array)\n",
    "predicted_class = train_gen.class_indices\n",
    "label_map = {v: k for k, v in predicted_class.items()}\n",
    "predicted_label = label_map[np.argmax(pred)]\n",
    "\n",
    "# Fetch nutritional data\n",
    "nutritional_info = nutri_dict.get(predicted_label, \"Data not found\")\n",
    "print(f\"Predicted: {predicted_label}\\nNutritional Info: {nutritional_info}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
