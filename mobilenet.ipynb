{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3200 images belonging to 80 classes.\n",
      "Found 800 images belonging to 80 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bennett Varghese\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 435ms/step - accuracy: 0.0177 - loss: 4.4994 - val_accuracy: 0.0425 - val_loss: 4.2832\n",
      "Epoch 2/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 470ms/step - accuracy: 0.0658 - loss: 4.1508 - val_accuracy: 0.0787 - val_loss: 4.0388\n",
      "Epoch 3/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 466ms/step - accuracy: 0.1407 - loss: 3.8355 - val_accuracy: 0.1488 - val_loss: 3.7249\n",
      "Epoch 4/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 473ms/step - accuracy: 0.2288 - loss: 3.4568 - val_accuracy: 0.2212 - val_loss: 3.4033\n",
      "Epoch 5/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 476ms/step - accuracy: 0.3278 - loss: 3.0391 - val_accuracy: 0.2600 - val_loss: 3.1217\n",
      "Epoch 6/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 481ms/step - accuracy: 0.3925 - loss: 2.6962 - val_accuracy: 0.3137 - val_loss: 2.8796\n",
      "Epoch 7/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 499ms/step - accuracy: 0.4509 - loss: 2.4655 - val_accuracy: 0.3562 - val_loss: 2.6962\n",
      "Epoch 8/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 501ms/step - accuracy: 0.5198 - loss: 2.1901 - val_accuracy: 0.3887 - val_loss: 2.5497\n",
      "Epoch 9/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 516ms/step - accuracy: 0.5485 - loss: 2.0152 - val_accuracy: 0.4112 - val_loss: 2.4351\n",
      "Epoch 10/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 527ms/step - accuracy: 0.5827 - loss: 1.8598 - val_accuracy: 0.4225 - val_loss: 2.3437\n",
      "Epoch 1/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 676ms/step - accuracy: 0.3462 - loss: 2.7300 - val_accuracy: 0.4450 - val_loss: 2.2631\n",
      "Epoch 2/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 658ms/step - accuracy: 0.4723 - loss: 2.3075 - val_accuracy: 0.4375 - val_loss: 2.2256\n",
      "Epoch 3/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 649ms/step - accuracy: 0.5298 - loss: 2.0427 - val_accuracy: 0.4387 - val_loss: 2.1883\n",
      "Epoch 4/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 676ms/step - accuracy: 0.5954 - loss: 1.8496 - val_accuracy: 0.4487 - val_loss: 2.1494\n",
      "Epoch 5/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 663ms/step - accuracy: 0.6133 - loss: 1.7122 - val_accuracy: 0.4575 - val_loss: 2.1107\n",
      "Epoch 6/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 696ms/step - accuracy: 0.6707 - loss: 1.5645 - val_accuracy: 0.4650 - val_loss: 2.0750\n",
      "Epoch 7/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 652ms/step - accuracy: 0.6948 - loss: 1.4381 - val_accuracy: 0.4688 - val_loss: 2.0333\n",
      "Epoch 8/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 646ms/step - accuracy: 0.7253 - loss: 1.3507 - val_accuracy: 0.4888 - val_loss: 1.9926\n",
      "Epoch 9/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 686ms/step - accuracy: 0.7423 - loss: 1.2797 - val_accuracy: 0.5063 - val_loss: 1.9540\n",
      "Epoch 10/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 729ms/step - accuracy: 0.7554 - loss: 1.2058 - val_accuracy: 0.5113 - val_loss: 1.9239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Paths\n",
    "data_dir = 'data'\n",
    "csv_path = 'indian_dishes_nutritional_values.csv'\n",
    "\n",
    "# Load nutrition data\n",
    "nutri_df = pd.read_csv(csv_path)\n",
    "nutri_dict = nutri_df.set_index(\"Dish Name\").to_dict(orient=\"index\")\n",
    "\n",
    "# Data generator\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Pretrained MobileNetV2\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(train_gen.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze base model for initial training\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_gen, validation_data=val_gen, epochs=10)\n",
    "\n",
    "# Fine-tune top layers\n",
    "for layer in base_model.layers[-40:]:  # Unfreeze last 40 layers\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_gen, validation_data=val_gen, epochs=10)\n",
    "\n",
    "model.save('fine_tuned_mobilenetv2_food_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829ms/step\n",
      "Predicted Dish: sutar_feni\n",
      "Nutritional Information: {'Calories(kcal)': 320, 'Carbohydrates(g)': 34, 'Protein(g)': 3, 'Fats(g)': 18, 'Sugar(g)': 25}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import os\n",
    "\n",
    "\n",
    "# --- Paths ---\n",
    "model_path = 'fine_tuned_mobilenetv2_food_model.h5'\n",
    "test_image_path = 'data/sutar_feni/2e2f921aa6.jpg'  # Replace with your test image\n",
    "csv_path = 'indian_dishes_nutritional_values.csv'\n",
    "img_size = (224, 224)\n",
    "\n",
    "# --- Load model and data ---\n",
    "model = load_model(model_path)\n",
    "nutri_df = pd.read_csv(csv_path)\n",
    "nutri_dict = nutri_df.set_index(\"Dish Name\").to_dict(orient=\"index\")\n",
    "\n",
    "# --- Load class labels ---\n",
    "class_labels = sorted(os.listdir('data'))\n",
    "\n",
    "# --- Predict image class ---\n",
    "img = load_img(test_image_path, target_size=img_size)\n",
    "x = img_to_array(img) / 255.0\n",
    "x = np.expand_dims(x, axis=0)\n",
    "pred = model.predict(x)\n",
    "label = class_labels[np.argmax(pred)]\n",
    "\n",
    "# --- Get nutrition info ---\n",
    "nutrition = nutri_dict.get(label, \"Nutrition data not found\")\n",
    "\n",
    "# --- Output result ---\n",
    "print(f\"Predicted Dish: {label}\")\n",
    "print(\"Nutritional Information:\", nutrition)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
